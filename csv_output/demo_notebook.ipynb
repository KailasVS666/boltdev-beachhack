{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AeroGuard Predictive Maintenance - End-to-End Demonstration\n",
    "\n",
    "This notebook demonstrates the complete AeroGuard system:\n",
    "1. Data processing with causal adjustments\n",
    "2. Model training with probabilistic outputs\n",
    "3. SHAP-based explainability\n",
    "4. Maintenance alert generation\n",
    "5. Work order creation\n",
    "6. Feedback loop simulation\n",
    "\n",
    "**Note**: This demo uses synthetic/mock data. For real deployment, use NASA C-MAPSS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# AeroGuard modules\n",
    "from data_processor import TurbofanDataProcessor\n",
    "from causal_engine import CausalEngine\n",
    "from aeroguard_model import AeroGuardModel, train_model\n",
    "from explainability import ExplainabilityEngine, generate_alerts_for_dataset\n",
    "from maintenance_integration import MaintenanceIntegration\n",
    "from feedback_system import FeedbackSystem, simulate_maintenance_workflow\n",
    "import config\n",
    "from utils import setup_logging, plot_rul_prediction\n",
    "\n",
    "# Setup\n",
    "logger = setup_logging('INFO')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"✓ AeroGuard modules loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Processing with Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic turbofan data for demonstration\n",
    "# In production, load real NASA C-MAPSS data:\n",
    "# processor = TurbofanDataProcessor()\n",
    "# data = processor.process_pipeline('data/train_FD001.txt')\n",
    "\n",
    "def create_synthetic_data(num_units=50, max_cycles=200):\n",
    "    \"\"\"Generate synthetic turbofan data\"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    for unit in range(1, num_units + 1):\n",
    "        cycles = np.random.randint(100, max_cycles)\n",
    "        \n",
    "        for cycle in range(1, cycles + 1):\n",
    "            # Operational settings\n",
    "            op1 = np.random.uniform(0, 1)  # Altitude\n",
    "            op2 = np.random.uniform(0, 1)  # Mach\n",
    "            op3 = np.random.uniform(0, 1)  # Throttle\n",
    "            \n",
    "            # Degradation factor (increases with cycles)\n",
    "            degradation = (cycles - cycle) / cycles  # 0 at failure, 1 at start\n",
    "            \n",
    "            # Sensors with degradation + environmental effects\n",
    "            T2 = 500 + 50 * op1 + (1 - degradation) * 20 + np.random.normal(0, 2)\n",
    "            T24 = 600 + 30 * op2 + (1 - degradation) * 25 + np.random.normal(0, 3)\n",
    "            T30 = 1500 + 100 * op3 + (1 - degradation) * 50 + np.random.normal(0, 5)\n",
    "            T50 = 1350 - 50 * op1 + (1 - degradation) * 60 + np.random.normal(0, 5)\n",
    "            \n",
    "            P2 = 14 - 5 * op1 + np.random.normal(0, 0.3)\n",
    "            P15 = 21 + 3 * op2 + np.random.normal(0, 0.4)\n",
    "            P30 = 550 + 50 * op3 + (1 - degradation) * 20 + np.random.normal(0, 2)\n",
    "            \n",
    "            Nf = 2400 + 200 * op3 + (1 - degradation) * 50 + np.random.normal(0, 10)\n",
    "            Nc = 9000 + 500 * op3 + (1 - degradation) * 100 + np.random.normal(0, 20)\n",
    "            \n",
    "            data_list.append([\n",
    "                unit, cycle, op1, op2, op3,\n",
    "                T2, T24, T30, T50, P2, P15, P30,\n",
    "                Nf, Nc,\n",
    "                P30/P2,  # epr\n",
    "                P30 - 10,  # Ps30\n",
    "                0.01 * op3,  # phi\n",
    "                Nf * 0.9, Nc * 0.9,  # NRf, NRc\n",
    "                2.5, 0.05, 100,  # BPR, farB, htBleed\n",
    "                Nf, Nf * 0.9,  # Nf_dmd, PCNfR_dmd\n",
    "                1.5, 1.2  # W31, W32\n",
    "            ])\n",
    "    \n",
    "    df = pd.DataFrame(data_list, columns=config.SENSOR_COLUMNS)\n",
    "    return df\n",
    "\n",
    "print(\"Creating synthetic turbofan data...\")\n",
    "synthetic_df = create_synthetic_data(num_units=30, max_cycles=150)\n",
    "print(f\"✓ Generated {len(synthetic_df)} observations for {synthetic_df['unit_number'].nunique()} engines\")\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processors\n",
    "processor = TurbofanDataProcessor()\n",
    "causal_engine = CausalEngine()\n",
    "\n",
    "# Calculate RUL\n",
    "df_with_rul = processor.calculate_rul(synthetic_df)\n",
    "\n",
    "# Apply causal adjustments\n",
    "df_causal = causal_engine.process_data_with_causal_adjustments(df_with_rul)\n",
    "\n",
    "# Engineer features\n",
    "df_features = processor.engineer_features(df_causal)\n",
    "\n",
    "print(f\"✓ Features engineered: {len(df_features.columns)} total columns\")\n",
    "print(f\"  Original sensors: {len(config.SENSOR_COLUMNS)}\")\n",
    "print(f\"  Engineered features: {len(df_features.columns) - len(config.SENSOR_COLUMNS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequences for LSTM\n",
    "X_sequences, y_rul, feature_names = processor.build_sequences(df_features)\n",
    "\n",
    "# Normalize\n",
    "X_normalized = processor.normalize_features(X_sequences, fit=True)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = processor.prepare_train_test_split(X_normalized, y_rul)\n",
    "\n",
    "print(f\"✓ Data prepared for training:\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val: {X_val.shape}\")\n",
    "print(f\"  Features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AeroGuard model\n",
    "model = AeroGuardModel(\n",
    "    num_features=len(feature_names),\n",
    "    causal_hidden_dim=64,\n",
    "    lstm_hidden_dim=128,\n",
    "    lstm_layers=2,\n",
    "    attention_heads=4\n",
    ")\n",
    "\n",
    "print(f\"✓ Model initialized\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (reduced epochs for demo)\n",
    "history = train_model(\n",
    "    model,\n",
    "    train_data={'X': X_train, 'y': y_train},\n",
    "    val_data={'X': X_val, 'y': y_val},\n",
    "    num_epochs=20,  # Increase to 100+ for production\n",
    "    batch_size=32,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training complete!\")\n",
    "print(f\"  Best RMSE: {history['best_rmse']:.2f} cycles\")\n",
    "print(f\"  Best epoch: {history['best_epoch'] + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(history['train_loss'], label='Train Loss')\n",
    "ax1.plot(history['val_loss'], label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training History - Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(history['val_rmse'], label='Val RMSE', color='orange')\n",
    "ax2.axhline(history['best_rmse'], color='red', linestyle='--', label=f'Best: {history['best_rmse']:.2f}')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('RMSE (cycles)')\n",
    "ax2.set_title('Validation RMSE')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predictions with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation set\n",
    "model.eval()\n",
    "X_val_tensor = torch.FloatTensor(X_val[:50])  # First 50 samples\n",
    "\n",
    "# Get predictions with uncertainty (MC Dropout)\n",
    "pred_mean, pred_std = model.predict_with_uncertainty(X_val_tensor, num_samples=50)\n",
    "\n",
    "# Plot predictions\n",
    "fig = plot_rul_prediction(\n",
    "    actual_rul=y_val[:50],\n",
    "    predicted_rul=pred_mean,\n",
    "    uncertainty=pred_std\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Prediction statistics:\")\n",
    "print(f\"  Mean RUL: {pred_mean.mean():.1f} ± {pred_std.mean():.1f} cycles\")\n",
    "print(f\"  Actual RUL: {y_val[:50].mean():.1f} cycles\")\n",
    "print(f\"  MAE: {np.abs(pred_mean - y_val[:50]).mean():.2f} cycles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Explainability (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize explainability engine\n",
    "explainer = ExplainabilityEngine(\n",
    "    model=model,\n",
    "    background_data=X_train[:100],  # Sample for SHAP\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "# Pick a sample with low RUL for demonstration\n",
    "low_rul_idx = np.argmin(y_val[:50])\n",
    "sample_sequence = X_val[low_rul_idx]\n",
    "sample_rul = y_val[low_rul_idx]\n",
    "\n",
    "print(f\"Analyzing Engine with RUL = {sample_rul:.0f} cycles...\")\n",
    "\n",
    "# Generate explanation\n",
    "explanation = explainer.explain_prediction(\n",
    "    sequence=sample_sequence,\n",
    "    actual_rul=sample_rul\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Explanation generated:\")\n",
    "print(f\"  Predicted RUL: {explanation['predicted_rul_mean']:.1f} ± {explanation['predicted_rul_std']:.1f}\")\n",
    "print(f\"  Actual RUL: {explanation['actual_rul']:.1f}\")\n",
    "print(f\"\\n  Top Contributing Sensors:\")\n",
    "for feat in explanation['top_features']:\n",
    "    print(f\"    • {feat['name']}: {feat['contribution_pct']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig = explainer.visualize_explanation(explanation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Maintenance Alert Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate maintenance alert\n",
    "alert = explainer.generate_maintenance_alert(\n",
    "    engine_id=5,\n",
    "    explanation=explanation,\n",
    "    confidence_level='conservative'\n",
    ")\n",
    "\n",
    "# Display formatted alert\n",
    "print(alert['alert_message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Work Order Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize maintenance integration\n",
    "maintenance = MaintenanceIntegration()\n",
    "\n",
    "# Generate work order\n",
    "work_order = maintenance.generate_work_order(\n",
    "    alert=alert,\n",
    "    aircraft_id='N54321',\n",
    "    flights_scheduled=8,\n",
    "    mechanic_id='TECH-ALPHA'\n",
    ")\n",
    "\n",
    "# Display formatted work order\n",
    "print(maintenance.format_work_order_for_print(work_order))\n",
    "\n",
    "print(f\"\\n✓ Work Order Details:\")\n",
    "print(f\"  Priority: {work_order['priority']} (Score: {work_order['priority_score']:.2f})\")\n",
    "print(f\"  Safe Flight Budget: {work_order['safe_flight_budget']:.0f} flights\")\n",
    "print(f\"  Estimated Downtime: {work_order['estimated_downtime_hours']} hours\")\n",
    "print(f\"  Parts Cost: ${work_order['total_parts_cost']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Feedback Loop Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feedback system\n",
    "feedback_system = FeedbackSystem()\n",
    "\n",
    "# Simulate maintenance workflow\n",
    "workflow = simulate_maintenance_workflow(\n",
    "    alert=alert,\n",
    "    work_order=work_order,\n",
    "    feedback_system=feedback_system,\n",
    "    technician_id='TECH-BRAVO'\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Workflow Summary:\")\n",
    "print(f\"  Alert ID: {workflow['alert_id']}\")\n",
    "print(f\"  Outcome: {workflow['outcome']}\")\n",
    "print(f\"  Technician: {workflow['technician_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multiple feedback submissions\n",
    "print(\"Simulating 20 alert feedback submissions...\\n\")\n",
    "\n",
    "for i in range(20):\n",
    "    # Create mock alert\n",
    "    mock_alert = {\n",
    "        'alert_id': f'AG-DEMO-{i:03d}',\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'engine_id': np.random.randint(1, 6),\n",
    "        'rul_mean': np.random.uniform(30, 100),\n",
    "        'rul_std': np.random.uniform(5, 15),\n",
    "        'top_sensors': [('T50', 0.4), ('Nc', 0.3)],\n",
    "        'recommended_action': 'Inspect turbine',\n",
    "        'priority': np.random.choice(['CRITICAL', 'HIGH', 'MEDIUM'])\n",
    "    }\n",
    "    \n",
    "    feedback_system.record_alert(mock_alert, f'WO-DEMO-{i:03d}')\n",
    "    \n",
    "    # Random outcome (80% confirmed, 15% false positive, 5% already known)\n",
    "    outcome = np.random.choice(\n",
    "        ['CONFIRMED', 'REJECTED_FALSE_POSITIVE', 'REJECTED_ALREADY_KNOWN'],\n",
    "        p=[0.80, 0.15, 0.05]\n",
    "    )\n",
    "    \n",
    "    feedback_system.submit_feedback(\n",
    "        alert_id=mock_alert['alert_id'],\n",
    "        outcome=outcome,\n",
    "        technician_id=f'TECH-{np.random.randint(1, 5):03d}',\n",
    "        technician_notes=f'Demo feedback for alert {i}'\n",
    "    )\n",
    "\n",
    "print(\"✓ Feedback simulation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance summary\n",
    "performance = feedback_system.get_performance_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AEROGUARD PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Alerts Issued: {performance['total_alerts']}\")\n",
    "print(f\"\\nOutcome Breakdown:\")\n",
    "print(f\"  ✓ Confirmed: {performance['confirmed']} ({performance['confirmed']/performance['total_alerts']*100:.1f}%)\")\n",
    "print(f\"  ✗ False Positives: {performance['rejected_false_positive']} ({performance['false_positive_rate']*100:.1f}%)\")\n",
    "print(f\"  ℹ Already Known: {performance['rejected_already_known']}\")\n",
    "print(f\"  ⏸ Deferred: {performance['deferred']}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Precision: {performance['precision']:.1%}\")\n",
    "print(f\"  Target Precision: {performance['target_precision']:.0%}\")\n",
    "print(f\"  Meets Target: {'✓ YES' if performance['meets_target_precision'] else '✗ NO'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check retraining readiness\n",
    "is_ready, analytics = feedback_system.prepare_retraining_data(min_samples=15)\n",
    "\n",
    "print(f\"\\n✓ Retraining Analysis:\")\n",
    "print(f\"  Feedback Samples: {analytics['total_feedback_samples']}\")\n",
    "print(f\"  Minimum Required: {analytics['min_required']}\")\n",
    "print(f\"  Ready for Retraining: {'✓ YES' if is_ready else '✗ NO'}\")\n",
    "\n",
    "if is_ready:\n",
    "    print(f\"\\n  → System ready for quarterly retraining with expert review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export feedback for expert review\n",
    "export_path = Path('feedback_export.csv')\n",
    "feedback_system.export_feedback_for_review(export_path)\n",
    "\n",
    "# Display sample\n",
    "feedback_df = pd.read_csv(export_path)\n",
    "print(f\"\\n✓ Feedback exported to {export_path}\")\n",
    "print(f\"\\nSample records:\")\n",
    "feedback_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demonstration showed the complete AeroGuard workflow:\n",
    "\n",
    "1. **✓ Data Processing**: Causal adjustments remove environmental noise\n",
    "2. **✓ ML Model**: Bi-LSTM with causal attention predicts RUL with uncertainty\n",
    "3. **✓ Explainability**: SHAP shows which sensors drove each prediction\n",
    "4. **✓ Maintenance Integration**: Alerts converted to actionable work orders\n",
    "5. **✓ Feedback Loop**: Non-punitive learning from technician feedback\n",
    "\n",
    "### Key Metrics\n",
    "- **Model RMSE**: ~{rmse} cycles on validation set\n",
    "- **Alert Precision**: {precision}% (target: 75%)\n",
    "- **System Status**: {status}\n",
    "\n",
    "### Next Steps for Production\n",
    "1. Train on full NASA C-MAPSS dataset (100+ epochs)\n",
    "2. Integrate with real-time aircraft data streams\n",
    "3. Deploy shadow mode alongside existing maintenance processes\n",
    "4. Collect 3-6 months of feedback for calibration\n",
    "5. Seek FAA/EASA advisory approval for supplemental use\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: AeroGuard is an *advisory system*. All maintenance decisions require certified technician approval per regulatory requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
